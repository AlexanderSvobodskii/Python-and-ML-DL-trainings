{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869bbbc8-969a-49c7-93ea-84290a13673d",
   "metadata": {},
   "source": [
    "# Inroduction\n",
    "\n",
    "The main idea of random forest is using of <b>bagging</b> in decision trees (parallel training some number of trees where a train dataset for each of them is some random subset of initial train dataset - for example, random 90% of initial dataset) with making predicates from random subset of set of features in each node of the tree (these features are chosen randomly in each node). In bagging itself and in random forest method in particular we must use deep trees.\n",
    "\n",
    "There are recommendation about what part of features you need to take in each node while building of the random forest:\n",
    "* For classification: $\\dfrac{1}{3}$ of size of initial set of features\n",
    "* For regression: square root of size of initial set of features\n",
    "\n",
    "Then we use majority vote (consider an object as belonged to a class accordance to class for which majority trees voted) for classification problems, and taking average for regression problems on otput of the model.\n",
    "\n",
    "Advantage of such approach is absence of overfitting - we can't overfit our model while increasing of nuumber of trees.\n",
    "\n",
    "Disadvantages of the method - fitting and obtaining of predictions takes much time (we must train all the trees and make prediction for our object on all the models) even with using of parallel training of the trees; sometimes the method create systematic errors despite of huge depth of our trees (it can be fixed sometimes by XGBoost)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb3437-facc-4d41-856e-bc815e58e539",
   "metadata": {},
   "source": [
    "# On the way to random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e4113-826d-49d6-b5fb-87672f4e6a5c",
   "metadata": {},
   "source": [
    "## Binary decision tree\n",
    "\n",
    "For start, let's build a decision tree without limits of depth on data of Boston dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e20d5-8df4-4ced-9a44-bdc0c62c9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed711092-3d6a-4a1f-a2dc-ea734ad16c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import boston_housing_data # right way to load boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0f6f1c-07c3-42b6-b9af-71b26a8b5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02ec5b5-d82b-40ae-84fb-e753575b282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = boston_housing_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3b673e-f1d9-4474-a655-ea38b78c35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0a7ed0-71cd-4ebf-8ea8-0f81c37581ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.084473684210526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a26960-6f87-42aa-84c0-ce61f2d46d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, dt.predict(X_train))\n",
    "\n",
    "# You can see zero error on tree, so the model is overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3164e-05e4-463c-839e-d042fcd041df",
   "metadata": {},
   "source": [
    "Let's look on deconposition of bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e796c38-642a-43bd-b886-a0df142e7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "883232dc-818e-424f-88d1-c4a83c627a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        dt, X_train, y_train, X_test, y_test, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1dd1be1-d0b5-4b3e-a3a7-10ef42902454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.26238322368421"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_expected_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ae9edb9-f749-4cc2-857e-09cfbb9ca35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.433280445723684"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b52d4b8-b5b2-4fb1-8cb4-b894168b29bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.829102777960525"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f623e7-3403-44a6-8ad9-0531e48d47ba",
   "metadata": {},
   "source": [
    "We can see that our tree is overfitted (large dispersion and low variance). We can fix it by using composition of trees trained on some subsets of initial train dataset - i.e. <b>bagging</b>.\n",
    "\n",
    "We will see further that composition of trees has the same variance as one tree but much more lower dispersion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9478781-5193-4ba3-884d-388eaf49f52f",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e2ef1c-c59e-4bd7-a19f-518d9f33d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e6e408-cb82-4233-b773-36d3c2b36846",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tree = DecisionTreeRegressor(random_state=123)\n",
    "\n",
    "# bagging with 20 trees\n",
    "bagging_regressor = BaggingRegressor(base_tree, 20)\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        bagging_regressor, X_train, y_train, X_test, y_test, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5372e274-65aa-4ecd-ae11-463eb156444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.601350712993423"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_expected_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "358074fa-814a-4f52-88e2-0315e05cf0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.408263925193266"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52361812-248c-467e-a2b5-c3db3a46b6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.193086787800165"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b84c62-56e3-4f76-b8a0-99d412d33876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.718313486842106"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, bagging_regressor.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76fda8e9-33f4-4fa1-84f6-c6d65dc58b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.225731779661018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, bagging_regressor.predict(X_train))\n",
    "\n",
    "# You can see non-zero error on tree, so the model isn't overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a025ab8-f75a-4571-80b6-d5c2d783f43b",
   "metadata": {},
   "source": [
    "And finally let's consider random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f18e80-e723-4176-adac-1a003761cc84",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "Compared to usual parameters in one decision tree building here we consider the following parameters:\n",
    "* `max_features` - number of features based on which you build your predicates in nodes of the trees\n",
    "* `n_estimators` - number of trees in random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "858eb4e8-d2e1-4fe3-a944-5249fbc116c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "becd82e8-d84d-4db9-a183-0c20cdaa09ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators=20)\n",
    "random_forest.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61ae630a-32b4-489b-b0fd-c67ce92ec555",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        random_forest, X_train, y_train, X_test, y_test, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86914cff-5a31-42b1-a240-b8155522eb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.69901223930921"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_expected_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f25acf90-a900-4bbe-b24b-814e0d296eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.761492524527148"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed807d70-4545-4e18-a899-898c63225c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9375197147820717"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23c7c4c7-dd5e-4abc-9704-d8f606ace138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.00887730263157"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, random_forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9b773f-20dc-48a0-9432-d4d665bc3f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.321338559322034"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, random_forest.predict(X_train))\n",
    "\n",
    "# You can see non-zero error on tree, so the model isn't overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561da8d-bd7b-454d-8874-d36b14a57a3d",
   "metadata": {},
   "source": [
    "As you can see the lowest avg_var has random forest and avg_bias almost the same in all the methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda2c89-a1df-4dec-84fa-17e4be76fb0d",
   "metadata": {},
   "source": [
    "### Out-of-bag error\n",
    "\n",
    "While making a random forest, the same way as in bagging, each tree is builded on bootstraped subset of initial train dataset by random choise with repeats. Some objects are included in this subset a few times and some objects aren't included in this subset at all. For each tree we can consider objects which weren't included into bootstraped subset and use it for validation.\n",
    "\n",
    "Average validation error from all the trees in this case is <b>Out-of-bag error</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45373bb2-70be-4090-8f9b-976463bb915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8760889947613861"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = boston_housing_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=123, oob_score=True)\n",
    "rf.fit(X_train, y_train)\n",
    "# oob_score_ is R2 error on objects not included into train subset for trees of the random forest\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454abaa1-d4e9-45b5-bf67-c55729ac41b4",
   "metadata": {},
   "source": [
    "As one decision tree, random forest can evaluate weights of the features, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fd15d2e-ed5b-4bf1-862c-02ec31d1078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0285272 , 0.00148259, 0.00466126, 0.00051459, 0.01864846,\n",
       "       0.50848227, 0.01436128, 0.05178391, 0.00490432, 0.01712143,\n",
       "       0.01432396, 0.00889071, 0.326298  ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfc68d-3d13-4cfc-95e3-61aaa087f920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
